services:
  mysql-hh:
    container_name: mysql-hh
    image: mysql
    environment:
      - MYSQL_DATABASE=Health-Hive
      - MYSQL_ROOT_PASSWORD=Password
    ports:
      - 3307:3306

    volumes:
      - ./docker/mysql/init.sql:/docker-entrypoint-initdb.d/1.sql
      - mysql_data:/var/lib/mysql

  keycloak-hh:
    container_name: keycloak-hh
    image: quay.io/keycloak/keycloak:22.0.1
    command:
      - "start-dev"
      - "--hostname-port=8080"
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_HOSTNAME: keycloak-hh
      KC_DB: mysql
      KC_DB_URL_HOST: mysql-hh
      KC_DB_URL_DATABASE: keycloak
      KC_DB_USERNAME: root
      KC_DB_PASSWORD: Password
      KC_HEALTH_ENABLED: true
      KC_METRICS_ENABLED: true
    ports:
      - "8080:8080"
    depends_on:
      - mysql-hh

  mysql-hp-exporter:
    container_name: mysql-hh-exporter
    image: quay.io/prometheus/mysqld-exporter
    command:
      - "--mysqld.username=root:Password"
      - "--mysqld.address=mysql-hp:3307"
    #environment:
    #  DATA_SOURCE_NAME: "root:P4ssword!@(mysql-hp:3306)/" # Adjust credentials and MySQL host/port
    ports:
      - '9104:9104'
    depends_on:
      - mysql-hh

  prometheus:
    image: prom/prometheus
    extra_hosts: [ 'host.docker.internal:host-gateway' ]
    command:
      - --enable-feature=exemplar-storage
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./docker/prometheus/rule.yml:/etc/prometheus/rule.yml:ro
    #      - token_volume:/app/tokens
    ports:
      - "9090:9090"
    depends_on:
      - mysql-hp-exporter
      - keycloak-hh

  grafana:
    image: grafana/grafana
    extra_hosts: [ 'host.docker.internal:host-gateway' ]
    volumes:
      - ./docker/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./docker/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    ports:
      - "3001:3000"
  ##################################################################################
  ## Cluster PEER 0 ################################################################
  ##################################################################################

  ipfs0:
    container_name: ipfs0
    image: ipfs/kubo:release
    ports:
      - "4001:4001" # ipfs swarm - expose if needed/wanted
      - "5001:5001" # ipfs api - expose if needed/wanted
    volumes:
      - ./compose/ipfs0:/data/ipfs

  cluster0:
    container_name: cluster0
    image: ipfs/ipfs-cluster:latest
    depends_on:
      - ipfs0
    environment:
      CLUSTER_PEERNAME: cluster0
      CLUSTER_SECRET: ${CLUSTER_SECRET} # From shell variable if set
      CLUSTER_IPFSHTTP_NODEMULTIADDRESS: /dns4/ipfs0/tcp/5001
      CLUSTER_CRDT_TRUSTEDPEERS: '*' # Trust all peers in Cluster
      CLUSTER_RESTAPI_HTTPLISTENMULTIADDRESS: /ip4/0.0.0.0/tcp/9094 # Expose API
      CLUSTER_MONITORPINGINTERVAL: 2s # Speed up peer discovery
    ports:
      # Open API port (allows ipfs-cluster-ctl usage on host)
      - "127.0.0.1:9094:9094"
      # The cluster swarm port would need  to be exposed if this container
      # was to connect to cluster peers on other hosts.
      # But this is just a testing cluster.
      - "9095:9095" # Cluster IPFS Proxy endpoint
      - "9096:9096" # Cluster swarm endpoint
    volumes:
      - ./compose/cluster0:/data/ipfs-cluster

  ##################################################################################
  ## Cluster PEER 1 ################################################################
  ##################################################################################

  # See Cluster PEER 0 for comments (all removed here and below)
  ipfs1:
    container_name: ipfs1
    image: ipfs/kubo:release
    volumes:
      - ./compose/ipfs1:/data/ipfs

  cluster1:
    container_name: cluster1
    image: ipfs/ipfs-cluster:latest
    depends_on:
      - ipfs1
    environment:
      CLUSTER_PEERNAME: cluster1
      CLUSTER_SECRET: ${CLUSTER_SECRET}
      CLUSTER_IPFSHTTP_NODEMULTIADDRESS: /dns4/ipfs1/tcp/5001
      CLUSTER_CRDT_TRUSTEDPEERS: '*'
      CLUSTER_MONITORPINGINTERVAL: 2s # Speed up peer discovery
    volumes:
      - ./compose/cluster1:/data/ipfs-cluster

  ##################################################################################
  ## Cluster PEER 2 ################################################################
  ##################################################################################

  # See Cluster PEER 0 for comments (all removed here and below)
  ipfs2:
    container_name: ipfs2
    image: ipfs/kubo:release
    volumes:
      - ./compose/ipfs2:/data/ipfs

  cluster2:
    container_name: cluster2
    image: ipfs/ipfs-cluster:latest
    depends_on:
      - ipfs2
    environment:
      CLUSTER_PEERNAME: cluster2
      CLUSTER_SECRET: ${CLUSTER_SECRET}
      CLUSTER_IPFSHTTP_NODEMULTIADDRESS: /dns4/ipfs2/tcp/5001
      CLUSTER_CRDT_TRUSTEDPEERS: '*'
      CLUSTER_MONITORPINGINTERVAL: 2s # Speed up peer discovery
    volumes:
      - ./compose/cluster2:/data/ipfs-cluster



# For adding more peers, copy PEER 1 and rename things to ipfs2, cluster2.
# Keep bootstrapping to cluster0.
volumes:

  mysql_data:



